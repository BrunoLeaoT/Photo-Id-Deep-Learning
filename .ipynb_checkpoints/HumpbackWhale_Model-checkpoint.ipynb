{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightInit(shape,dtype=None):\n",
    "    \"\"\"Initialize weights\"\"\"\n",
    "    return rng.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def biasInit(shape,dtype=None):\n",
    "    \"\"\"Initialize bias\"\"\"\n",
    "    return rng.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "input_shape = (300, 300, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,kernel_initializer=weightInit,kernel_regularizer=l2(2e-4)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=weightInit,bias_initializer=biasInit))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=weightInit,kernel_regularizer=l2(2e-4),bias_initializer=biasInit))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=weightInit,kernel_regularizer=l2(2e-4),bias_initializer=biasInit))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=weightInit,bias_initializer=biasInit))\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=biasInit)(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "optimizer = Adam(0.00006)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 300, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 300, 300, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 4096)         944917312   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 4096)         0           sequential[0][0]                 \n",
      "                                                                 sequential[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            4097        lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 944,921,409\n",
      "Trainable params: 944,921,409\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DatasetPrepare.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "createLabelsTargets = CreateLabelsTargets(\"train_HB.csv\")\n",
    "createLabelsTargets.load_csv_and_treat() \n",
    "(X_train, X_test, y_train, y_test) = createLabelsTargets.create_labels_and_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPath= os.getcwd()+'/modelHB_imgs/train/'\n",
    "# Creating training data generator\n",
    "dataTrainLoader = DataLoader(imagesPath,X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 16.0% 5 way one-shot learning accuracy\n",
      "iteration 50, loss: 67.07, val_acc: 16.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 22.0% 5 way one-shot learning accuracy\n",
      "iteration 100, loss: 45.91, val_acc: 22.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 29.0% 5 way one-shot learning accuracy\n",
      "iteration 150, loss: 31.66, val_acc: 29.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 23.0% 5 way one-shot learning accuracy\n",
      "iteration 200, loss: 22.09, val_acc: 23.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 16.0% 5 way one-shot learning accuracy\n",
      "iteration 250, loss: 15.63, val_acc: 16.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 16.0% 5 way one-shot learning accuracy\n",
      "iteration 300, loss: 11.23, val_acc: 16.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 21.0% 5 way one-shot learning accuracy\n",
      "iteration 350, loss: 8.20, val_acc: 21.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 29.0% 5 way one-shot learning accuracy\n",
      "iteration 400, loss: 6.11, val_acc: 29.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 33.0% 5 way one-shot learning accuracy\n",
      "iteration 450, loss: 4.66, val_acc: 33.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 19.0% 5 way one-shot learning accuracy\n",
      "iteration 500, loss: 3.65, val_acc: 19.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 23.0% 5 way one-shot learning accuracy\n",
      "iteration 550, loss: 2.93, val_acc: 23.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 29.0% 5 way one-shot learning accuracy\n",
      "iteration 600, loss: 2.42, val_acc: 29.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 25.0% 5 way one-shot learning accuracy\n",
      "iteration 650, loss: 2.05, val_acc: 25.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 24.0% 5 way one-shot learning accuracy\n",
      "iteration 700, loss: 1.78, val_acc: 24.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 16.0% 5 way one-shot learning accuracy\n",
      "iteration 750, loss: 1.58, val_acc: 16.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 26.0% 5 way one-shot learning accuracy\n",
      "iteration 800, loss: 1.42, val_acc: 26.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 23.0% 5 way one-shot learning accuracy\n",
      "iteration 850, loss: 1.31, val_acc: 23.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 32.0% 5 way one-shot learning accuracy\n",
      "iteration 900, loss: 1.22, val_acc: 32.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 36.0% 5 way one-shot learning accuracy\n",
      "iteration 950, loss: 1.15, val_acc: 36.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n",
      "Got an average of 24.0% 5 way one-shot learning accuracy\n",
      "iteration 1000, loss: 1.09, val_acc: 24.00\n",
      "Evaluating model on 100 random 5 way one-shot learning tasks ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd26778d9e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlossHistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataTrainLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_oneshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msiamese_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_way\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mloss_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-5ba4375ffc40>\u001b[0m in \u001b[0;36mtest_oneshot\u001b[0;34m(self, model, N, k, X, y, verbose)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_oneshot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;31m#             print(\"Probs\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m#             print(probs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "evaluate_every = 50 # interval for evaluating on one-shot tasks\n",
    "loss_every= 50 # interval for printing loss (iterations)\n",
    "batch_size = 16\n",
    "epochs = 9000\n",
    "N_way = 5 # how many classes for testing one-shot tasks\n",
    "n_val = 100 #number of one-shot tasks to validate on\n",
    "lossHistory = []\n",
    "print(\"training\")\n",
    "for i in range(1, epochs):\n",
    "    (inputs,targets)=dataTrainLoader.getBatch(batch_size)\n",
    "    (loss)=siamese_net.train_on_batch(inputs,targets)\n",
    "    lossHistory.append(loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        val_acc = dataTrainLoader.test_oneshot(siamese_net,N_way,n_val,X_test,y_test,verbose=True)\n",
    "\n",
    "    if i % loss_every == 0:\n",
    "        print(\"iteration {}, loss: {:.2f}, val_acc: {:.2f}\".format(i,loss,val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD9CAYAAACyYrxEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHoVJREFUeJzt3Xl0XOWd5vHvr6q0y9plLV5kGxkbs9jGAkwbCGDCQIAYAmGZLA5h2ukMk5BlThKmuyc9y5mBnnSA9KRJ3GELyQAJJIFhCIQYCAGDscTq3fJu2ZLlTZJtyVKp3vmjroxQZGypJN2qW8/nnDpV971vVf3uuTpPXb11673mnENERIIr5HcBIiIyuhT0IiIBp6AXEQk4Bb2ISMAp6EVEAk5BLyIScCcMejN70Mz2mNmqfm0lZvaimW307ou9djOzH5lZo5m9b2Znj2bxIiJyYidzRP8wcMWAtu8By5xz04Fl3jLAlcB077YEuH9kyhQRkeE6YdA7514F9g9oXgQ84j1+BLi2X/vPXdybQJGZVY1UsSIiMnTDHaOvcM7t9h43AxXe4wnAjn79dnptIiLik0iiL+Ccc2Y25HkUzGwJ8eEd8vLy5s2cOTPRUkRE0kpDQ8Ne51z5ifoNN+hbzKzKObfbG5rZ47U3AZP69Zvotf0F59xSYClAXV2dq6+vH2YpIiLpycy2nUy/4Q7dPAMs9h4vBp7u1/5F7+yb+UBbvyEeERHxwQmP6M3sMeBioMzMdgLfB+4CfmVmtwHbgBu97s8BnwIagSPAraNQs4iIDMEJg945d8txVi0cpK8Dbk+0KBERGTn6ZayISMAp6EVEAk5BLyIScAp6EZGAS+mgb9h2gLufX4eueysicnwpHfSrd7Vx/yub2L7/iN+liIgkrZQO+gW1ZQC81rjX50pERJJXSgf9tLI8KguyWd64z+9SRESSVkoHvZmxoLaM1zftJRbTOL2IyGBSOugBLpheysEjPazZ3e53KSIiSSnlg/7cqaUA1G8deG0UERGBAAT9hKIcqgqzqd92wO9SRESSUsoHPUDdlBLqtx7Q+fQiIoMIRtDXFNPc3kXTwU6/SxERSTrBCPopxQDUb9XwjYjIQIEI+pmVBeRnRajfpi9kRUQGCkTQh0PG3MlFOqIXERlEIIIeoK6mhPUtHbR19vhdiohIUglM0J8zpRjn4O3tOqoXEekvMEE/Z3IR4ZDRoOEbEZGPCEzQ52ZGmFVVoC9kRUQGCEzQA8yrKebdHQfp6Y35XYqISNIIVNDXTSmmqyfGWk1wJiJyTLCCvqYE0A+nRET6C1TQVxZmM6EohwZNcCYickyggh7i4/T12/ZrgjMREU/ggr5uSjEt7UfZeUATnImIQACDfl5NfIIz/XBKRCQucEE/s7KAvMywvpAVEfEELujjE5wV64pTIiKewAU9xIdv1je309GlCc5ERAIZ9HVTiok5eGf7Qb9LERHxXSCDfu7kYkKGzqcXESHBoDezb5rZajNbZWaPmVm2mU01sxVm1mhmT5hZ5kgVe7LysyLMrCxQ0IuIkEDQm9kE4OtAnXPuDCAM3AzcDdzjnKsFDgC3jUShQzWvpph3th8gqgnORCTNJTp0EwFyzCwC5AK7gUuBJ731jwDXJvgew1I3pZjD3b2sa+7w4+1FRJLGsIPeOdcE/ADYTjzg24AG4KBzLup12wlMSLTI4ej74ZSGb0Qk3SUydFMMLAKmAtVAHnDFEJ6/xMzqzay+tbV1uGUc14SiHCoLshX0IpL2Ehm6uQzY4pxrdc71AL8BFgBF3lAOwESgabAnO+eWOufqnHN15eXlCZQxODNj3pRiBb2IpL1Egn47MN/Mcs3MgIXAGuBl4Aavz2Lg6cRKHL55k4tpOtjJ7jZNcCYi6SuRMfoVxL90fRv4wHutpcB3gW+ZWSNQCjwwAnUOS92U+Di95r0RkXQWOXGX43POfR/4/oDmzcC5ibzuSDmtqoCcjDAN2w5wzexqv8sREfFFIH8Z2ycjHGLu5CJWbt3vdykiIr4JdNADnDu1hDW722nr1ARnIpKeAh/0500txTmo11G9iKSpwAf93MlFZEZCvLl5n9+liIj4IvBBn50RZs6kIlZs0RG9iKSnwAc9wPxppaxqaqNdFyIRkTSUHkE/tYSYgwadTy8iaSgtgn7u5GIywsabWzROLyLpJy2CPiczPk7/5maN04tI+kmLoIf4aZarmto4dDR64s4iIgGSPkE/rYTemNNsliKSdtIm6OfVFBMJmc6nF5G0kzZBn5sZ4ayJhaxQ0ItImkmboAc4b1op7+9s40i3xulFJH2kVdDPn1ZKNOZYqfPpRSSNpFXQnzMlfj798sa9fpciIjJm0iroczMjnD25mNcU9CKSRtIq6AEuqC1j9a529h/u9rsUEZExkXZBv2B6GQDLN+moXkTSQ9oF/VkTChmXFeF1Dd+ISJpIu6CPhEPMP6VU4/QikjbSLughPk6/Y38n2/cd8bsUEZFRl5ZBv6A2Pk6vo3oRSQdpGfSnlOdRWZCtcXoRSQtpGfRmxgXTy3itcS/R3pjf5YiIjKq0DHqAi2eU09bZw3s7D/pdiojIqErboL+wtpxwyHh5XavfpYiIjKq0DfrC3AzmTS7mlQ17/C5FRGRUpW3QA3xiRjmrmtrZ097ldykiIqMmrYP+khnjAXhlg4ZvRCS40jroT6saR0VBFn9ar6AXkeBK66A3My6ZMZ5XN7bSo9MsRSSg0jroIX6aZUdXlLe36apTIhJMCQW9mRWZ2ZNmts7M1prZ+WZWYmYvmtlG7754pIodDQtqy4iETOP0IhJYiR7R3wc875ybCcwG1gLfA5Y556YDy7zlpDUuO4NzppTw8jqdZikiwTTsoDezQuAi4AEA51y3c+4gsAh4xOv2CHBtokWOtktmlrOuuYPdbZ1+lyIiMuISOaKfCrQCD5nZO2b2MzPLAyqcc7u9Ps1ARaJFjra+0yxf0lG9iARQIkEfAc4G7nfOzQUOM2CYxjnnADfYk81siZnVm1l9a6u/4+O14/OpKc3lxTUtvtYhIjIaEgn6ncBO59wKb/lJ4sHfYmZVAN79oIfJzrmlzrk651xdeXl5AmUkzsy4fFYFyxv30dHV42stIiIjbdhB75xrBnaY2QyvaSGwBngGWOy1LQaeTqjCMfLJWZV098b4k86+EZGAiST4/K8BvzSzTGAzcCvxD49fmdltwDbgxgTfY0zMqymmJC+TF9e0cPVZ1X6XIyIyYhIKeufcu0DdIKsWJvK6fgiHjIUzx/P86ma6ozEyI2n/WzIRCQilWT+Xn15JR1eUFVv2+V2KiMiIUdD3c0FtGdkZIZ19IyKBoqDvJyczzEXTy/nD6hZisUHPChURSTkK+gGuPLOS5vYu3tmhSc5EJBgU9ANcdloFmZEQ//e93SfuLCKSAhT0A4zLzuDiU8t57oPdGr4RkUBQ0A/i6tnV7Ok4ysqt+/0uRUQkYQr6QSycOZ7sjBD/7wMN34hI6lPQDyIvK8KlM8fz3AfN9Gr4RkRSnIL+OK4+q5q9h47qx1MikvIU9MdxyYzx5GaGefZ9Dd+ISGpT0B9HTmaYhadV8PyqZqK9Mb/LEREZNgX9x7jqzCr2H+7mjc0avhGR1KWg/xgXzyhnXHaE377d5HcpIiLDpqD/GNkZYa6ZXc1zq3brylMikrIU9Cfw2XkT6eqJ8fsPmv0uRURkWBT0JzBnUhGnlOfx64YdfpciIjIsCvoTMDNumDeJlVsPsHXvYb/LEREZMgX9Sbhu7gRCBk+9vdPvUkREhkxBfxIqC7O5cHo5TzXs1IyWIpJyFPQn6YZ5E9nV1sXyTTqnXkRSi4L+JH1yVgUF2RGe1JeyIpJiFPQnKTsjzKfnVPP86mbadU69iKQQBf0Q3DBvEl09MZ7TRGcikkIU9EMwe2IhtePzeaJewzcikjoU9ENgZtxy7mTe2X6QVU1tfpcjInJSFPRDdMO8ieRkhHn0jW1+lyIiclIU9ENUmJPBtXOrefq9JtqO6EtZEUl+Cvph+Pz8Grp6Ypr/RkRSgoJ+GE6vLmReTTG/eHObfikrIklPQT9MXzy/hq37jvDnxr1+lyIi8rEU9MN0xRmVlOVn8ugbW/0uRUTkYynohykrEuamcyaxbN0eduw/4nc5IiLHlXDQm1nYzN4xs2e95almtsLMGs3sCTPLTLzM5PT5+TWEzXjw9S1+lyIiclwjcUR/B7C23/LdwD3OuVrgAHDbCLxHUqoqzOHTc6p5/K0dHDjc7Xc5IiKDSijozWwicBXwM2/ZgEuBJ70ujwDXJvIeyW7JRdPo7OnlF2/qB1QikpwSPaK/F/gOEPOWS4GDzrmot7wTmJDgeyS1mZUFXDKjnIeXb6Wrp9fvckRE/sKwg97Mrgb2OOcahvn8JWZWb2b1ra2twy0jKXzlE6ew73A3TzboUoMiknwSOaJfAHzazLYCjxMfsrkPKDKziNdnItA02JOdc0udc3XOubry8vIEyvDfeVNLmDOpiH/982Z69QMqEUkyww5659ydzrmJzrkpwM3AS865zwEvAzd43RYDTydcZZIzM/7mE9PYtu8Iz69q9rscEZGPGI3z6L8LfMvMGomP2T8wCu+RdD45q5KpZXn8yyuNOKejehFJHiMS9M65V5xzV3uPNzvnznXO1TrnPuucOzoS75HswiHj9ktqWb2rnRfXtPhdjojIMfpl7Ai6dk41U0pzufePG3VULyJJQ0E/giLhEF+7dDprdrfzwmod1YtIclDQj7BFc6qZWpbHvX/coCmMRSQpKOhHWCQc4usLa1nX3MELq3UGjoj4T0E/Cq45q5pp5Xn84A/rifbGTvwEEZFRpKAfBZFwiO9eMZNNrYd5ol6XGxQRfynoR8nlsyqoqynmnhc3cvho9MRPEBEZJQr6UWJm/KerTmPvoaMsfXWz3+WISBpT0I+isycXc9WZVSx9dTN72rv8LkdE0pSCfpR954oZRGMx7vnjRr9LEZE0paAfZTWleXx+fg1PrNzOml3tfpcjImlIQT8G7lg4naLcTP7+6VX6EZWIjDkF/Rgoys3kzitn0rDtgC5OIiJjTkE/Rq4/eyLnTCnmf/5+rS4kLiJjSkE/RkIh479dewbtXVH+8YV1fpcjImlEQT+GZlYW8OUFU3jsrR28vf2A3+WISJpQ0I+xOy47lcqCbP72t6vo0Tw4IjIGFPRjLD8rwn9ddDprd7fzv19q9LscEUkDCnofXH56JdfNncCPX25kVVOb3+WISMAp6H3yD9ecTkleJt/+1Xscjfb6XY6IBJiC3ieFuRncdf2ZrG/p4EfLND2CiIweBb2PLp1ZwWfnTeT+Vzbx7o6DfpcjIgGloPfZ318zi8qCbL75xLsc0rz1IjIKFPQ+K8jO4N6b57Jt32H+7rcf4JzmwhGRkaWgTwLnTi3hG5edyu/e3cWvNReOiIwwBX2SuP2SWv7qlFL+89Or2NjS4Xc5IhIgCvokEQ4Z9940h7zMCP/+l29rvF5ERoyCPomML8jmvpvnsqn1EP/xV+9pvF5ERoSCPslcML2MO688jedXN/PjlzVFgogkTkGfhP7dhVNZNKeaf3pxAy+ta/G7HBFJcQr6JGRm3PWZs5hVVcDX/s87rN6l+XBEZPgU9EkqJzPMA4vPoSAngy8/vJJdBzv9LklEUpSCPolVFmbz0K3ncORoL7c+tJL2rh6/SxKRFDTsoDezSWb2spmtMbPVZnaH115iZi+a2Ubvvnjkyk0/MysL+MkX5rGp9RBf/UUD3VFdrEREhiaRI/oo8G3n3CxgPnC7mc0Cvgcsc85NB5Z5y5KABbVl3H39WbzeuI+v/qJB0xqLyJAMO+idc7udc297jzuAtcAEYBHwiNftEeDaRIsUuH7eRP77tWewbN0elvy8ga4ehb2InJwRGaM3synAXGAFUOGc2+2tagYqRuI9BD4/v4a7PnMmr25s5a9/Xq+wF5GTknDQm1k+8BTwDedce/91Lv7TzkF/3mlmS8ys3szqW1tbEy0jbdx87mTuvv4sXmvcy5cfXklnt8JeRD5eQkFvZhnEQ/6XzrnfeM0tZlblra8C9gz2XOfcUudcnXOurry8PJEy0s6NdZP4p8/O5s3N+7j14bc4rHlxRORjJHLWjQEPAGudcz/st+oZYLH3eDHw9PDLk+P5zNkTueemOby1ZT9feugtTYImIseVyBH9AuALwKVm9q53+xRwF/BJM9sIXOYtyyhYNGcC9908l7e3H+SLD6zQefYiMqjIcJ/onHsNsOOsXjjc15WhuWZ2NZGQ8bXH3uHGn7zBg186h+qiHL/LEpEkol/GBsCVZ1bx4JfOYeeBTq77l9dZ1aS5cUTkQwr6gLjo1HKe/Or5hM248adv8MLqZr9LEpEkoaAPkJmVBfzu9gVMH5/PVx5t4H+9sI7emC5eIpLuFPQBM74gmye+cj431U3ixy9v4ssPr+TgkW6/yxIRHynoAyg7I8xd15/J/7juTJZv2svV//waDdsO+F2WiPhEQR9QZsa/PW8yv/rK+QDc+NM3+NGyjRrKEUlDCvqAmzu5mOfuuJCrz6rihy9u4Jalb9Kki5iIpBUFfRooyM7gvpvncs9Ns1m9q40r7nmVR9/YSkxH9yJpQUGfRq6bO5Hf33ERZ00q5O+fXs31P1nOuub2Ez9RRFKagj7NTC7N5Re3ncc9N81m274jXP2j17jr9+s0C6ZIgCno05CZcd3ciSz71if4zNkT+MmfNnH5vX/ilfWDTjQqIilOQZ/GivMy+ccbZvP4kvlkhEN86aGVfOGBFZpCQSRgFPTC/Gml/P6OC/m7q07jg6Y2rv7n17jj8XfYvu+I36WJyAiw+EWg/FVXV+fq6+v9LkOA9q4efvLKJh58fQu9Mcfnzqvh9ktqKR+X5XdpIjKAmTU45+pO2E9BL4NpbuvivmUbeGLlDiLhEDfMm8hfXziNqWV5fpcmIh4FvYyIza2H+Nc/b+Gpt3fS0xvjitMrWXLRNOZOLva7NJG0p6CXEbWno4tHlm/l0Te20d4V5dypJfzNJ6Zx8anjCYWOd/0ZERlNCnoZFYeORnli5Q4e+PNmdrV1UVOay03nTOKGeRMZPy7b7/JE0oqCXkZVT2+M5z7YzS9XbOetLfuJhIyFp43n5nMnc9H0csI6yhcZdScb9MO+Zqykt4xwiEVzJrBozgQ2tR7iiZU7eKphJy+sbqF8XBZXnVnFp+dUM3dSEWYKfRE/6YheRkx3NMaytS08/e4uXlq/h+5ojEklOVx9VjWXz6pg9sQijeeLjCAN3Yiv2rt6+MPqFp55bxevN+6lN+Yoy89i4czxXDarggtqy8jJDPtdpkhKU9BL0mg70sMrG/bw4poW/rS+lY6jUbIiIS6oLeOC6WUsqC1j+vh8DfGIDJHG6CVpFOZmHBvP747GeGvLfv64toWX1u1h2br4RGrl47JYcEopf1UbD/4JRTk+Vy0SHDqiF1/t2H+E5Zv28nrjPpZv2sveQ/ELmU8szmFeTTHzaoo5e3Ixp1aMIzOiqZlE+tPQjaQc5xzrWzpY3riP+m37qd96gD0dRwHIDIeYWTWOMyYUcqZ3U/hLulPQS8pzztF0sJN3th9kVVMbH3i3jq4oEA//GZXjmFE5jlMr8pleMY5TK8ZRXZit8X5JCwp6CSTnHNv3H+H9nW2sampj1a42NrQcotU78gfIz4owvSKf2vJ8ppTlMaU0j5rSXGpKcxmXneFj9SIjS1/GSiCZGTWledSU5nHN7Opj7QcOd7OhpYMNew6xsaWDDS0dvLy+lb0NOz/y/LL8TO/5uUwpzWNySS5VhdlUF+VQUZCtoSAJJAW9BEJxXibnTSvlvGmlH2k/fDTKtn1H2LbvMFuP3R/mjU37+M3bTR/pawbl+VlUFeVQXZhNVWEO1UXZVBZmM35cNmX5mZSPyyI/K6KhIUkpCnoJtLysCLOqC5hVXfAX67p6etl5oJPdbZ3sOtjJroNd7G7rZHdbFxtaOnhlfSudPX950fTsjBDl47Ioy8+iNC+T4txMSvLit+K8TEpyMynJj98X52UyLiuiXwSLrxT0krayM8LUjs+ndnz+oOudc7R19tDc3sXejm5aD3XR2nH0w9uho+w62MWqpnb2H+6muzd23PcalxWhICeDcdkRCrIzKMiJMC47g4Js7z4n3t7/cV5WhJzMMDkZYXIzw2RFQvpPQoZFQS9yHGZGUW4mRbmZUPnxfZ1zHOnuZf/h7vjtSDf7D3Vz4Eg3HV1R2rt6aO+M0tHVQ3tXD7sOdtFxtONYW+wkz4nIyQgfC//sjFC/x+GPrDt27z0euD57QJ/MSIiMsJEZCcVvYX2oBMmoBL2ZXQHcB4SBnznn7hqN9xFJFmZGXlaEvKwIk0pyh/Rc5xyHu3tp74x/CHR0RWnv7OHQ0ShdPb10dvfS2ROjs6eXrp5ejnRH6eyOxdd56zu6orR2HD223Ne3p3f4Z9VFQkZGOEQkbGR69xnhkHczIqEQGZEQGSfqF45/cERCNqB/iHAIQmZEQkY4ZIRC8cchiy8fu/Vb7uszWFvf8yJeW3jg63htob7nGRiGWbyOvvuQEagPuhEPejMLAz8GPgnsBFaa2TPOuTUj/V4iQWBm5GdFyM+KUM3ITv3Q0/vRD4SBHwSd3TGOdEfp6XX09MbojsY4Gu09thy/xR9H+9pijp5ojGgsRnevI+r16+wZ2C9GT9TF+0VjRGPu2OulimMfAHz4QfDhh0G83QxCof59+j4w6NfHCIXiHyp97Xj3dyyc/pEzyEbDaBzRnws0Ouc2A5jZ48AiQEEvMsb6jqyT6fcDzjmiMUe019HrHL0xRywWb4t5y8duA5cHtPU9r9f1e42Ped6x/t57OQcxBw7vcczhgJhz8eE07z7mPmx3Lr4Nx9r7LTu8+2Ov3bfc16fvdeLrcFCYM/r7ZjSCfgKwo9/yTuC8UXgfEUlBZkZG2MjQLNVjxrdfh5jZEjOrN7P61tZWv8oQEQm80Qj6JmBSv+WJXttHOOeWOufqnHN15eXlo1CGiIjA6AT9SmC6mU01s0zgZuCZUXgfERE5CSM+Ru+ci5rZfwBeIH565YPOudUj/T4iInJyRuU8eufcc8Bzo/HaIiIyNJqqT0Qk4BT0IiIBp6AXEQm4pLjClJm1AtuG+fQyYO8IlpOstJ3Bou0MFr+2s8Y5d8Lz05Mi6BNhZvUncymtVKftDBZtZ7Ak+3Zq6EZEJOAU9CIiAReEoF/qdwFjRNsZLNrOYEnq7Uz5MXoREfl4QTiiFxGRj5HSQW9mV5jZejNrNLPv+V1PIsxskpm9bGZrzGy1md3htZeY2YtmttG7L/bazcx+5G37+2Z2tr9bcPLMLGxm75jZs97yVDNb4W3LE95keJhZlrfc6K2f4mfdQ2VmRWb2pJmtM7O1ZnZ+QPfnN72/2VVm9piZZQdhn5rZg2a2x8xW9Wsb8v4zs8Ve/41mttiPbUnZoO93ycIrgVnALWY2y9+qEhIFvu2cmwXMB273tud7wDLn3HRgmbcM8e2e7t2WAPePfcnDdgewtt/y3cA9zrla4ABwm9d+G3DAa7/H65dK7gOed87NBGYT3+ZA7U8zmwB8Hahzzp1BfCLDmwnGPn0YuGJA25D2n5mVAN8nfvGlc4Hv9304jKn4Ja9S7wacD7zQb/lO4E6/6xrB7Xua+HV31wNVXlsVsN57/FPgln79j/VL5hvx6xMsAy4FngWM+A9NIgP3K/EZUM/3Hke8fub3NpzkdhYCWwbWG8D92XdFuRJvHz0L/Jug7FNgCrBquPsPuAX4ab/2j/Qbq1vKHtEz+CULJ/hUy4jy/p2dC6wAKpxzu71VzUCF9zhVt/9e4DtAzFsuBQ4656Lecv/tOLaN3vo2r38qmAq0Ag95w1Q/M7M8ArY/nXNNwA+A7cBu4vuogWDuUxj6/kuK/ZrKQR9IZpYPPAV8wznX3n+dix8SpOxpUmZ2NbDHOdfgdy1jIAKcDdzvnJsLHObDf/OB1N+fAN4wxCLiH2zVQB5/OdwRSKm0/1I56E/qkoWpxMwyiIf8L51zv/GaW8ysyltfBezx2lNx+xcAnzazrcDjxIdv7gOKzKzv2gj9t+PYNnrrC4F9Y1lwAnYCO51zK7zlJ4kHf5D2J8BlwBbnXKtzrgf4DfH9HMR9CkPff0mxX1M56AN1yUIzM+ABYK1z7of9Vj0D9H1Tv5j42H1f+xe9b/vnA239/qVMSs65O51zE51zU4jvr5ecc58DXgZu8LoN3Ma+bb/B658SR1DOuWZgh5nN8JoWAmsI0P70bAfmm1mu9zfct52B26eeoe6/F4DLzazY++/ncq9tbPn9ZUeCX5R8CtgAbAL+1u96EtyWC4j/G/g+8K53+xTx8ctlwEbgj0CJ19+In3W0CfiA+FkPvm/HELb3YuBZ7/E04C2gEfg1kOW1Z3vLjd76aX7XPcRtnAPUe/v0d0BxEPcn8F+AdcAq4FEgKwj7FHiM+PcOPcT/Q7ttOPsP+LK3vY3ArX5si34ZKyIScKk8dCMiIidBQS8iEnAKehGRgFPQi4gEnIJeRCTgFPQiIgGnoBcRCTgFvYhIwP1/ZpcCDdkGy/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossHistory)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usar evaluate para ver loss\n",
    "# passar no teste x_train e X_test, para ver se é overfitting\n",
    "#suspeita de overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (300, 300, 1)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "#build convnet to use in each siamese neural newtork\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,(5,5), padding='same',activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64,(4,4), padding='same',activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128,(3,3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128,(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(256,(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(428,activation=\"sigmoid\"))#voltar pra 4096?\n",
    "\n",
    "\n",
    "#call the convnet Sequential model on each of the input tensors so params will be shared\n",
    "encoded_l = model(left_input)\n",
    "encoded_r = model(right_input)\n",
    "#layer to merge two encoded inputs with the l1 distance between them\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "#call this layer on list of two input tensors.\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(0.1)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
