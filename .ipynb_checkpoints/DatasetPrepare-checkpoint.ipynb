{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import numpy.random as rng\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateLabelsTargets:\n",
    "    def __init__(self,path):\n",
    "        self.df = pd.read_csv(path)\n",
    "        columns = list(self.df.columns.values)\n",
    "        \n",
    "        # Treating the columns in the csv for the two possible options\n",
    "        if(columns[0] == 'Image'):\n",
    "            self.columnImage = columns[0]\n",
    "            self.columnId = columns[1]\n",
    "        else:\n",
    "            self.columnImage = columns[1]\n",
    "            self.columnId = columns[0]\n",
    "        \n",
    "        self.numberOfClasses = self.df[self.columnId].nunique()\n",
    "    def load_csv_and_treat(self):\n",
    "        self.dict_classes = {}\n",
    "        for index, row in self.df.iterrows():\n",
    "            #print(row['Image'], row['Id'])\n",
    "            if(row[self.columnId] == 'new_whale' or row[self.columnImage] == 'new_whale'):\n",
    "                continue\n",
    "            if (not self.dict_classes.get(row[self.columnId])):\n",
    "                self.dict_classes[row[self.columnId]] = []\n",
    "            auxArray = self.dict_classes.get(row[self.columnId])\n",
    "            auxArray.append(row[self.columnImage])\n",
    "            self.dict_classes[row[self.columnId]] = auxArray\n",
    "    def create_labels_and_targets(self):\n",
    "        X=[]\n",
    "        y=[]\n",
    "        for key, value in self.dict_classes.items():\n",
    "            X.append(value)\n",
    "            y.append(key)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "        return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "    \n",
    "    def create_dataset_with_image(self,imgsPath):\n",
    "        X=[]\n",
    "        y=[]\n",
    "        IMG_DIM = (200,200)\n",
    "        for key, values in self.dict_classes.items():\n",
    "            for value in values:\n",
    "                fullPath = imgsPath + value\n",
    "                img = load_img(fullPath, color_mode = \"grayscale\",target_size=IMG_DIM)\n",
    "                X.append(img_to_array(img))\n",
    "                y.append(key)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "        return (np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test))\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    def __init__(self, path, X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "        self.w = 200\n",
    "        self.h = 200\n",
    "        self.datagen = ImageDataGenerator( \n",
    "            rotation_range = 40, \n",
    "            shear_range = 0.2, \n",
    "            zoom_range = 0.2, \n",
    "            horizontal_flip = True, \n",
    "            brightness_range = (0.5, 1.5))\n",
    "        \n",
    "    def loadImageAsArray(self,name):\n",
    "        fullPath = self.path + name\n",
    "        img = load_img(fullPath, color_mode = \"grayscale\")\n",
    "        return img_to_array(img)\n",
    "    \n",
    "    def getBatch(self,batch_size):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        n_classes = len(self.y)\n",
    "        IMG_DIM = (self.w,self.h)\n",
    "        #randomly sample several classes to use in the batch\n",
    "        categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "        #initialize 2 empty arrays for the input image batch\n",
    "        pairs=[np.zeros((batch_size, self.w, self.h,1)) for i in range(2)]\n",
    "        #initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "        targets=np.zeros((batch_size,))\n",
    "        targets[batch_size//2:] = 1\n",
    "        for i in range(batch_size):\n",
    "            category = categories[i]\n",
    "            #If category doesnt have two examples, it wont be good to equal test\n",
    "            if (i >= batch_size // 2) and (len(self.X[category]) == 1):  \n",
    "                while(len(self.X[category]) == 1):\n",
    "                    categories = rng.choice(n_classes,size=(batch_size,),replace=False)\n",
    "                    category = categories[i]\n",
    "            \n",
    "            #Select first image\n",
    "            n_examples = len(self.X[category])\n",
    "            idx_1 = rng.randint(0, n_examples)\n",
    "            fullPath = self.path + self.X[category][idx_1]\n",
    "            img = load_img(fullPath, color_mode = \"grayscale\",target_size=IMG_DIM)\n",
    "            pairs[0][i,:,:,:] = img_to_array(img)\n",
    "\n",
    "            #pick category and index of same class for 1st half, different for 2nd\n",
    "            if i >= batch_size // 2:\n",
    "                category_2 = category\n",
    "                idx_2 = (idx_1 + rng.randint(1,n_examples)) % n_examples\n",
    "            else: \n",
    "                #add old category number to the category modulo n classes to ensure 2nd image has different category\n",
    "                category_2 = (category + rng.randint(1,n_classes)) % n_classes\n",
    "                n_examples = len(self.X[category_2])\n",
    "                idx_2 = rng.randint(0, n_examples)\n",
    "            \n",
    "            fullPath = self.path + self.X[category_2][idx_2]\n",
    "            img = load_img(fullPath, color_mode = \"grayscale\",target_size=IMG_DIM)\n",
    "            pairs[1][i,:,:,:] = img_to_array(img)\n",
    "            \n",
    "            # augmentation on data\n",
    "            pair = rng.randint(0,1)\n",
    "            augs = self.datagen.flow(pairs[pair], batch_size=1,shuffle=False)\n",
    "            for i in range(len(augs)):\n",
    "                pairs[pair][i,:,:,:] = augs[i][0]\n",
    "\n",
    "        return pairs, targets\n",
    "\n",
    "    def generate(self, batch_size):\n",
    "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = self.getBatch(batch_size)\n",
    "            yield (pairs, targets)\n",
    "            \n",
    "    def make_oneshot_task(self,N,X,y):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        n_classes = len(y)\n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "        true_category = categories[0]\n",
    "        if(len(X[true_category]) == 1):\n",
    "            while(len(X[true_category]) == 1):\n",
    "                categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "                true_category = categories[0]\n",
    "\n",
    "        n_examples = len(X[true_category])\n",
    "        ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "        \n",
    "        # Load Image\n",
    "        testImage = self.loadImageAsArray(X[true_category][ex1])\n",
    "        testImage = np.asarray([testImage]*N)\n",
    "#         print(\"Category\", str(true_category))\n",
    "#         print(\"Index:\", str(ex1))\n",
    "        # Get first image equal to original\n",
    "        supportSet = []\n",
    "        supportSet.append(img_to_array(self.loadImageAsArray(X[true_category][ex2])))\n",
    "#         print(\"Category\", str(true_category))\n",
    "#         print(\"Index:\", str(ex2))\n",
    "        #Append the rest of the test images\n",
    "        for category in categories:\n",
    "            if(category == true_category):\n",
    "                continue\n",
    "            n_examples = len(X[category])\n",
    "            index = rng.randint(0,n_examples)\n",
    "            setImage = img_to_array(self.loadImageAsArray(X[category][index]))\n",
    "            supportSet.append(setImage)\n",
    "#             print(\"Category\", str(category))\n",
    "#             print(\"Index:\", str(index))\n",
    "        supportSet = np.array(supportSet)\n",
    "        #initialize targets equal zero\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, testImage, supportSet = shuffle(targets, testImage, supportSet)\n",
    "#         print(\"Targets after shuffle\")\n",
    "#         print(targets)\n",
    "        pairs = [testImage,supportSet]\n",
    "#         for index in range(len(pairs[0])):\n",
    "#             imgplot = plt.imshow(array_to_img(pairs[0][index]), cmap='gray')\n",
    "#             plt.title(str(index) + \"_ \" + str(targets[index]) + \"_ \"  + y[true_category])\n",
    "#             plt.show()\n",
    "#             imgplot2 = plt.imshow(array_to_img(pairs[1][index]), cmap='gray')\n",
    "#             plt.title(str(index) + \"_ \" + str(targets[index]) + \"_ \"  + y[categories[index]])\n",
    "#             plt.show()\n",
    "        return pairs, targets\n",
    "    \n",
    "    def test_oneshot(self,model,N,k,X,y,verbose=0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ...\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.make_oneshot_task(N,X,y)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "createLabelsTargets = CreateLabelsTargets(\"train_HB.csv\")\n",
    "createLabelsTargets.load_csv_and_treat()\n",
    "(X_train, X_test, y_train, y_test) = createLabelsTargets.create_labels_and_targets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataLoad = DataLoader(os.getcwd()+'/modelHB_imgs/train/',X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pairs,targets) = dataLoad.make_oneshot_task(5,X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(pairs,targets) = dataLoad.getBatch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index in range(len(pairs[0])):\n",
    "    imgplot = plt.imshow(array_to_img(pairs[0][index]), cmap='gray')\n",
    "    plt.title(str(index) + \"_ \" + str(targets[index]))\n",
    "    plt.show()\n",
    "    imgplot2 = plt.imshow(array_to_img(pairs[1][index]), cmap='gray')\n",
    "    plt.title(str(index) + \"_ \" + str(targets[index]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSetTriplet(imgsPath, csvPath):\n",
    "    \"\"\"Build dataset for train and test using triplet loss\n",
    "    \"\"\"\n",
    "    createLabelsTargets = CreateLabelsTargets(csvPath)\n",
    "    createLabelsTargets.load_csv_and_treat()\n",
    "    (X_train, X_test, y_train, y_test) = createLabelsTargets.create_dataset_with_image(imgsPath)\n",
    "    width = 200\n",
    "    height = 200\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], width, height, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], width, height, 1)\n",
    "    print(X_train)\n",
    "    print(X_test)\n",
    "    dataset_train = []\n",
    "    dataset_test = []\n",
    "    \n",
    "    #Sorting images by classes and normalize values 0=>1\n",
    "    for n in range(createLabelsTargets.numberOfClasses):\n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(X_train_origin) if y_train_origin[idx]==n])\n",
    "        dataset_train.append(images_class_n/255)\n",
    "        \n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(X_test_origin) if y_test_origin[idx]==n])\n",
    "        dataset_test.append(images_class_n/255)\n",
    "        \n",
    "    return dataset_train,dataset_test,X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]]\n",
      "[[[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]\n",
      "\n",
      "\n",
      " [[[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]\n",
      "\n",
      "  [[255.]\n",
      "   [255.]\n",
      "   [255.]\n",
      "   ...\n",
      "   [255.]\n",
      "   [255.]\n",
      "   [255.]]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_origin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-650b9e81c15a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbuildDataSetTriplet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/modelHB_imgs/train/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train_HB.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-50-4863d6c5d245>\u001b[0m in \u001b[0;36mbuildDataSetTriplet\u001b[1;34m(imgsPath, csvPath)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#Sorting images by classes and normalize values 0=>1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreateLabelsTargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumberOfClasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mimages_class_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_origin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my_train_origin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_class_n\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_origin' is not defined"
     ]
    }
   ],
   "source": [
    "buildDataSetTriplet(os.getcwd()+'/modelHB_imgs/train/','train_HB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
